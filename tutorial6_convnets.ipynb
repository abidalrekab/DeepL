{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tutorial6-convnets.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abidalrekab/DeepL/blob/master/tutorial6_convnets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFYFac2yNGez",
        "colab_type": "text"
      },
      "source": [
        "## Convolutional Neural Networks\n",
        "In this exercise you will:\n",
        "1. Complete the design of a convolutional neural network similar to the classic LeNet from http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf .\n",
        "2. Use cross-validation to determine the optimal number of filters/activation maps per layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzrOhhrDN_g_",
        "colab_type": "text"
      },
      "source": [
        "This model will train best on a GPU.  Google Colab is <b>highly recommended</b>.  See our Slack #homework channel for how to enable the GPU runtime on Colab.    \n",
        "\n",
        "Let's get started.  Note the use of PyTorch dataset samplers.  You'll want to familiarize yourself with them by reading the docs: https://pytorch.org/docs/stable/data.html."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERrGJ3jxQpsM",
        "colab_type": "text"
      },
      "source": [
        "<b>Important Note</b>:  Consider this notebook 'starter code'.  You will need to extend it, alter it, and in some cases replace it.  Please write whatever code you need to in order to correctly solve the problem!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFphj-TzLL9E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c776c29e-c681-4254-d6bd-dbac6f33b866"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SequentialSampler\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "print(device)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKwloNzlPfi8",
        "colab_type": "text"
      },
      "source": [
        "Note the 2-D input_size.  We are preparing to read the MNIST dataset and resizing the images to 32x32 pixels with zero padding includes.  They are grayscale already, so the input will be 32x32x1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZnh3mfSNV2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyper Parameters \n",
        "input_size = (32, 32)\n",
        "num_classes = 10\n",
        "num_epochs = 25\n",
        "batch_size_train = 256\n",
        "batch_size_val = 256\n",
        "batch_size_test = 1024\n",
        "learning_rate = 2e-3\n",
        "num_folds = 6  # V-fold cross validation!\n",
        "v = 1  # The filter hyperparameter.  The number of activation maps is dependent.\n",
        "torch.set_printoptions(threshold=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoI3ercORU1T",
        "colab_type": "text"
      },
      "source": [
        "This initially downloads two datasets, one for training and validation (called train_dataset) and one for test.  You will eventually need to split the training data into training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjvAEX-WLvzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load image data and transform images to 32x32x1\n",
        "train_dataset = dsets.MNIST(root='./data',\n",
        "                         train=True,\n",
        "                         transform=transforms.Compose([\n",
        "                             transforms.Resize(input_size),\n",
        "                             transforms.ToTensor()]),\n",
        "                         download=True)\n",
        "test_dataset = dsets.MNIST('./data',\n",
        "                        train=False,\n",
        "                        transform=transforms.Compose([\n",
        "                            transforms.Resize(input_size),\n",
        "                            transforms.ToTensor()]),\n",
        "                        download=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMMlJI8hNVBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset loaders (handle mini-batching of data) \n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size_train, shuffle=True) \n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size_test, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXA3Fe_g42M_",
        "colab_type": "text"
      },
      "source": [
        "Here is a CNN model architecture, missing some layers.  See the problem statement for guidance on how to complete it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y78iY-1lQfdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet5(nn.Module):\n",
        "    # A version of LeNet-5.  Note the hyperparameter 'v' (n^v activation maps).\n",
        "    def __init__(self, v=0):\n",
        "        super(LeNet5, self).__init__()\n",
        "        # 1 image input channel, 6 filters, 5x5 kernel\n",
        "        self.convnet = nn.Sequential(\n",
        "            nn.Conv2d(1, 2**v, kernel_size=(5, 5)),                        # c1\n",
        "            nn.ReLU(),  # relu1\n",
        "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),                    # s2\n",
        "            nn.Conv2d(2**v, 3**v, kernel_size=(5, 5)),                     # c3\n",
        "            nn.ReLU(),  # relu3\n",
        "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),                    # s4\n",
        "            nn.Conv2d(3**v, 5**v, kernel_size=(5, 5),stride = 1),          # c5\n",
        "            nn.ReLU()                                                    # relu5\n",
        "           \n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(5**v, 84),                                  #f6\n",
        "            nn.ReLU(),                                                    # relu5\n",
        "            nn.Linear(84, 10)                                               #f7\n",
        "    \n",
        "        )\n",
        "        \n",
        "    def forward(self, input):\n",
        "        convout = self.convnet(input)\n",
        "        convout = convout.view(input.size(0), -1)\n",
        "        output = self.fc(convout)\n",
        "        return output\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH8eRsX25g21",
        "colab_type": "text"
      },
      "source": [
        "The followign function will train the model for a single epoch and report the training loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku8iA2cdbduQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_one_epoch(epoch_num):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad() \n",
        "        outputs = model(images) \n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        # Optimize\n",
        "        optimizer.step()\n",
        "        if (i + 1) % 10 == 0:\n",
        "            print('Epoch: [% d/% d], Step: [% d/% d], Loss: %.4f'\n",
        "                  % (epoch_num + 1, num_epochs, i + 1,\n",
        "                     len(train_dataset) // batch_size_train, loss.item())) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uRXmaKj5vst",
        "colab_type": "text"
      },
      "source": [
        "The following functions are provided for your convenience.  They compute the error and accuracy of all data supplied  via a loader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-7_tFN7mbOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_error(loader, length, split='validation'):\n",
        "    \"\"\" Computes the loss for all data points in a loader.\n",
        "       \n",
        "        Inputs:\n",
        "            loader: Pytorch data loader (object)\n",
        "            length: Number of data points (integer)\n",
        "            split: Name of split, typically 'train', 'test', or 'validation' (string)\n",
        "        \n",
        "        Returns:\n",
        "            loss (floating point)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    # Measure the error for the entire loader split.\n",
        "    i = 0\n",
        "    loss = 0.\n",
        "    num_batches = 0\n",
        "    for images, labels in loader:  # One batch at a time!\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss += criterion(outputs, labels).item()\n",
        "        # print(f'Batch loss is {criterion(outputs, labels)}')\n",
        "        num_batches += 1\n",
        "\n",
        "    print(f'Error of the model on the {length} {split} images: {loss / num_batches: .6f}')\n",
        "    return loss / num_batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuuhGQZKdi7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_accuracy(loader, dataset, split='train'):\n",
        "    model.eval()\n",
        "    # Measure the accuracy for the entire test dataset \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images) \n",
        "        _, predicted = torch.max(outputs.data, 1) \n",
        "        total += labels.size(0) \n",
        "        correct += (predicted == labels).sum()\n",
        "        acc = float(correct) / total\n",
        "    print(f'Accuracy of the model on the {len(dataset)} {split} images: {float(correct) / total:3.1%}') \n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFrwsRx56I9r",
        "colab_type": "text"
      },
      "source": [
        "This procedure will initialize the model and run a training loop.  You will eventually need to implement it within a cross validation loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDHcLUbL5GTy",
        "colab_type": "text"
      },
      "source": [
        "This is a 10-class classification problem.  We will use the popular Adam optimizer.  More about Adam here: https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs9C8jGYuVSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc_train = np.array(np.zeros((num_epochs)))\n",
        "acc_test = np.array(np.zeros((num_epochs)))\n",
        "def run_training():\n",
        "    # Re-initialize model and optimizer!\n",
        "    global model, criterion, optimizer, v, acc\n",
        "    model = LeNet5(v).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    for epoch in range(num_epochs):\n",
        "        train_one_epoch(epoch)\n",
        "        acc_train[epoch] = epoch_accuracy(test_loader, test_dataset, 'test')\n",
        "        acc_test[epoch] = epoch_accuracy(train_loader, train_dataset, 'train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42NesFlBel8R",
        "colab_type": "text"
      },
      "source": [
        "<b>Problem 5(a): </b>  Complete the convolutional neural network and verify it trains.\n",
        "1.  Add a 3rd convolutional layer.  The layer should have ```5**v``` activation maps (filter sets), where ```v``` is an integer.  Use a 5x5 filter (kernel) and a stride of 1.  This layer will follow s4 and be called c5.  Use a ReLU activation function.  This will be called relu5.\n",
        "2.  Add the fully connected layers for cross entropy classification.  Implement two nn.Linear layers: f6 and f7, with a ReLU activation for f6 (called relu6).  f7 is the output and should not have a non-linear activation since that will be handled by nn.CrossEntropyLoss().  f6 should have ```5**v``` inputs and 84 outputs.  f7 should have 10 outputs for the 10 classes of the classifier.\n",
        "3.  Show your new model code (above, where originally implemented in the starter code) and verify that it trains.  Set hyperparameter ```v = 1``` and training the model on all of the training data (60,000 images) for 10 epochs.  Report the training and test (10,000 images) accuracy.\n",
        "4.  With ```v = 1```, is this model high bias, high variance, or both?  Assume we should be able to exceed 99% accuracy on this task.  Explain using your training and test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwmihiACh-ge",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10851
        },
        "outputId": "0462120d-f44c-4bc0-9c9f-ab1842340f73"
      },
      "source": [
        "# Your results here.\n",
        "run_training()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [ 1/ 25], Step: [ 10/ 234], Loss: 2.2953\n",
            "Epoch: [ 1/ 25], Step: [ 20/ 234], Loss: 2.2985\n",
            "Epoch: [ 1/ 25], Step: [ 30/ 234], Loss: 2.2625\n",
            "Epoch: [ 1/ 25], Step: [ 40/ 234], Loss: 2.1622\n",
            "Epoch: [ 1/ 25], Step: [ 50/ 234], Loss: 1.8744\n",
            "Epoch: [ 1/ 25], Step: [ 60/ 234], Loss: 1.4862\n",
            "Epoch: [ 1/ 25], Step: [ 70/ 234], Loss: 1.3509\n",
            "Epoch: [ 1/ 25], Step: [ 80/ 234], Loss: 1.0721\n",
            "Epoch: [ 1/ 25], Step: [ 90/ 234], Loss: 1.0562\n",
            "Epoch: [ 1/ 25], Step: [ 100/ 234], Loss: 1.0341\n",
            "Epoch: [ 1/ 25], Step: [ 110/ 234], Loss: 1.1090\n",
            "Epoch: [ 1/ 25], Step: [ 120/ 234], Loss: 0.8720\n",
            "Epoch: [ 1/ 25], Step: [ 130/ 234], Loss: 0.8693\n",
            "Epoch: [ 1/ 25], Step: [ 140/ 234], Loss: 0.9400\n",
            "Epoch: [ 1/ 25], Step: [ 150/ 234], Loss: 0.8770\n",
            "Epoch: [ 1/ 25], Step: [ 160/ 234], Loss: 0.8682\n",
            "Epoch: [ 1/ 25], Step: [ 170/ 234], Loss: 0.8766\n",
            "Epoch: [ 1/ 25], Step: [ 180/ 234], Loss: 0.9156\n",
            "Epoch: [ 1/ 25], Step: [ 190/ 234], Loss: 0.9314\n",
            "Epoch: [ 1/ 25], Step: [ 200/ 234], Loss: 0.7440\n",
            "Epoch: [ 1/ 25], Step: [ 210/ 234], Loss: 0.7095\n",
            "Epoch: [ 1/ 25], Step: [ 220/ 234], Loss: 0.7325\n",
            "Epoch: [ 1/ 25], Step: [ 230/ 234], Loss: 0.8096\n",
            "Accuracy of the model on the 10000 test images: 73.4%\n",
            "Accuracy of the model on the 60000 train images: 73.4%\n",
            "Epoch: [ 2/ 25], Step: [ 10/ 234], Loss: 0.8770\n",
            "Epoch: [ 2/ 25], Step: [ 20/ 234], Loss: 0.8358\n",
            "Epoch: [ 2/ 25], Step: [ 30/ 234], Loss: 0.7815\n",
            "Epoch: [ 2/ 25], Step: [ 40/ 234], Loss: 0.7677\n",
            "Epoch: [ 2/ 25], Step: [ 50/ 234], Loss: 0.8188\n",
            "Epoch: [ 2/ 25], Step: [ 60/ 234], Loss: 0.6304\n",
            "Epoch: [ 2/ 25], Step: [ 70/ 234], Loss: 0.8094\n",
            "Epoch: [ 2/ 25], Step: [ 80/ 234], Loss: 0.7296\n",
            "Epoch: [ 2/ 25], Step: [ 90/ 234], Loss: 0.7540\n",
            "Epoch: [ 2/ 25], Step: [ 100/ 234], Loss: 0.6868\n",
            "Epoch: [ 2/ 25], Step: [ 110/ 234], Loss: 0.5617\n",
            "Epoch: [ 2/ 25], Step: [ 120/ 234], Loss: 0.6608\n",
            "Epoch: [ 2/ 25], Step: [ 130/ 234], Loss: 0.5934\n",
            "Epoch: [ 2/ 25], Step: [ 140/ 234], Loss: 0.6932\n",
            "Epoch: [ 2/ 25], Step: [ 150/ 234], Loss: 0.7172\n",
            "Epoch: [ 2/ 25], Step: [ 160/ 234], Loss: 0.7459\n",
            "Epoch: [ 2/ 25], Step: [ 170/ 234], Loss: 0.5929\n",
            "Epoch: [ 2/ 25], Step: [ 180/ 234], Loss: 0.7073\n",
            "Epoch: [ 2/ 25], Step: [ 190/ 234], Loss: 0.6238\n",
            "Epoch: [ 2/ 25], Step: [ 200/ 234], Loss: 0.6592\n",
            "Epoch: [ 2/ 25], Step: [ 210/ 234], Loss: 0.5667\n",
            "Epoch: [ 2/ 25], Step: [ 220/ 234], Loss: 0.6583\n",
            "Epoch: [ 2/ 25], Step: [ 230/ 234], Loss: 0.7724\n",
            "Accuracy of the model on the 10000 test images: 78.6%\n",
            "Accuracy of the model on the 60000 train images: 78.2%\n",
            "Epoch: [ 3/ 25], Step: [ 10/ 234], Loss: 0.6005\n",
            "Epoch: [ 3/ 25], Step: [ 20/ 234], Loss: 0.6162\n",
            "Epoch: [ 3/ 25], Step: [ 30/ 234], Loss: 0.6483\n",
            "Epoch: [ 3/ 25], Step: [ 40/ 234], Loss: 0.6794\n",
            "Epoch: [ 3/ 25], Step: [ 50/ 234], Loss: 0.5345\n",
            "Epoch: [ 3/ 25], Step: [ 60/ 234], Loss: 0.6071\n",
            "Epoch: [ 3/ 25], Step: [ 70/ 234], Loss: 0.5597\n",
            "Epoch: [ 3/ 25], Step: [ 80/ 234], Loss: 0.6156\n",
            "Epoch: [ 3/ 25], Step: [ 90/ 234], Loss: 0.6325\n",
            "Epoch: [ 3/ 25], Step: [ 100/ 234], Loss: 0.5478\n",
            "Epoch: [ 3/ 25], Step: [ 110/ 234], Loss: 0.6622\n",
            "Epoch: [ 3/ 25], Step: [ 120/ 234], Loss: 0.5113\n",
            "Epoch: [ 3/ 25], Step: [ 130/ 234], Loss: 0.5646\n",
            "Epoch: [ 3/ 25], Step: [ 140/ 234], Loss: 0.7491\n",
            "Epoch: [ 3/ 25], Step: [ 150/ 234], Loss: 0.5266\n",
            "Epoch: [ 3/ 25], Step: [ 160/ 234], Loss: 0.5931\n",
            "Epoch: [ 3/ 25], Step: [ 170/ 234], Loss: 0.5706\n",
            "Epoch: [ 3/ 25], Step: [ 180/ 234], Loss: 0.5563\n",
            "Epoch: [ 3/ 25], Step: [ 190/ 234], Loss: 0.5858\n",
            "Epoch: [ 3/ 25], Step: [ 200/ 234], Loss: 0.5886\n",
            "Epoch: [ 3/ 25], Step: [ 210/ 234], Loss: 0.5275\n",
            "Epoch: [ 3/ 25], Step: [ 220/ 234], Loss: 0.5650\n",
            "Epoch: [ 3/ 25], Step: [ 230/ 234], Loss: 0.6225\n",
            "Accuracy of the model on the 10000 test images: 81.2%\n",
            "Accuracy of the model on the 60000 train images: 80.8%\n",
            "Epoch: [ 4/ 25], Step: [ 10/ 234], Loss: 0.5670\n",
            "Epoch: [ 4/ 25], Step: [ 20/ 234], Loss: 0.5555\n",
            "Epoch: [ 4/ 25], Step: [ 30/ 234], Loss: 0.5141\n",
            "Epoch: [ 4/ 25], Step: [ 40/ 234], Loss: 0.5145\n",
            "Epoch: [ 4/ 25], Step: [ 50/ 234], Loss: 0.6105\n",
            "Epoch: [ 4/ 25], Step: [ 60/ 234], Loss: 0.5542\n",
            "Epoch: [ 4/ 25], Step: [ 70/ 234], Loss: 0.5463\n",
            "Epoch: [ 4/ 25], Step: [ 80/ 234], Loss: 0.6197\n",
            "Epoch: [ 4/ 25], Step: [ 90/ 234], Loss: 0.6569\n",
            "Epoch: [ 4/ 25], Step: [ 100/ 234], Loss: 0.4750\n",
            "Epoch: [ 4/ 25], Step: [ 110/ 234], Loss: 0.5874\n",
            "Epoch: [ 4/ 25], Step: [ 120/ 234], Loss: 0.5555\n",
            "Epoch: [ 4/ 25], Step: [ 130/ 234], Loss: 0.5472\n",
            "Epoch: [ 4/ 25], Step: [ 140/ 234], Loss: 0.6757\n",
            "Epoch: [ 4/ 25], Step: [ 150/ 234], Loss: 0.5748\n",
            "Epoch: [ 4/ 25], Step: [ 160/ 234], Loss: 0.6616\n",
            "Epoch: [ 4/ 25], Step: [ 170/ 234], Loss: 0.4183\n",
            "Epoch: [ 4/ 25], Step: [ 180/ 234], Loss: 0.5433\n",
            "Epoch: [ 4/ 25], Step: [ 190/ 234], Loss: 0.5292\n",
            "Epoch: [ 4/ 25], Step: [ 200/ 234], Loss: 0.5830\n",
            "Epoch: [ 4/ 25], Step: [ 210/ 234], Loss: 0.5652\n",
            "Epoch: [ 4/ 25], Step: [ 220/ 234], Loss: 0.5421\n",
            "Epoch: [ 4/ 25], Step: [ 230/ 234], Loss: 0.5379\n",
            "Accuracy of the model on the 10000 test images: 82.9%\n",
            "Accuracy of the model on the 60000 train images: 82.5%\n",
            "Epoch: [ 5/ 25], Step: [ 10/ 234], Loss: 0.5386\n",
            "Epoch: [ 5/ 25], Step: [ 20/ 234], Loss: 0.5315\n",
            "Epoch: [ 5/ 25], Step: [ 30/ 234], Loss: 0.4678\n",
            "Epoch: [ 5/ 25], Step: [ 40/ 234], Loss: 0.5082\n",
            "Epoch: [ 5/ 25], Step: [ 50/ 234], Loss: 0.5452\n",
            "Epoch: [ 5/ 25], Step: [ 60/ 234], Loss: 0.6152\n",
            "Epoch: [ 5/ 25], Step: [ 70/ 234], Loss: 0.5302\n",
            "Epoch: [ 5/ 25], Step: [ 80/ 234], Loss: 0.5572\n",
            "Epoch: [ 5/ 25], Step: [ 90/ 234], Loss: 0.6178\n",
            "Epoch: [ 5/ 25], Step: [ 100/ 234], Loss: 0.5035\n",
            "Epoch: [ 5/ 25], Step: [ 110/ 234], Loss: 0.4681\n",
            "Epoch: [ 5/ 25], Step: [ 120/ 234], Loss: 0.5550\n",
            "Epoch: [ 5/ 25], Step: [ 130/ 234], Loss: 0.6263\n",
            "Epoch: [ 5/ 25], Step: [ 140/ 234], Loss: 0.4887\n",
            "Epoch: [ 5/ 25], Step: [ 150/ 234], Loss: 0.6620\n",
            "Epoch: [ 5/ 25], Step: [ 160/ 234], Loss: 0.5042\n",
            "Epoch: [ 5/ 25], Step: [ 170/ 234], Loss: 0.4914\n",
            "Epoch: [ 5/ 25], Step: [ 180/ 234], Loss: 0.4535\n",
            "Epoch: [ 5/ 25], Step: [ 190/ 234], Loss: 0.4673\n",
            "Epoch: [ 5/ 25], Step: [ 200/ 234], Loss: 0.5407\n",
            "Epoch: [ 5/ 25], Step: [ 210/ 234], Loss: 0.5053\n",
            "Epoch: [ 5/ 25], Step: [ 220/ 234], Loss: 0.5577\n",
            "Epoch: [ 5/ 25], Step: [ 230/ 234], Loss: 0.4580\n",
            "Accuracy of the model on the 10000 test images: 83.7%\n",
            "Accuracy of the model on the 60000 train images: 83.5%\n",
            "Epoch: [ 6/ 25], Step: [ 10/ 234], Loss: 0.6221\n",
            "Epoch: [ 6/ 25], Step: [ 20/ 234], Loss: 0.5395\n",
            "Epoch: [ 6/ 25], Step: [ 30/ 234], Loss: 0.5525\n",
            "Epoch: [ 6/ 25], Step: [ 40/ 234], Loss: 0.5489\n",
            "Epoch: [ 6/ 25], Step: [ 50/ 234], Loss: 0.5336\n",
            "Epoch: [ 6/ 25], Step: [ 60/ 234], Loss: 0.5139\n",
            "Epoch: [ 6/ 25], Step: [ 70/ 234], Loss: 0.4007\n",
            "Epoch: [ 6/ 25], Step: [ 80/ 234], Loss: 0.3981\n",
            "Epoch: [ 6/ 25], Step: [ 90/ 234], Loss: 0.4423\n",
            "Epoch: [ 6/ 25], Step: [ 100/ 234], Loss: 0.5881\n",
            "Epoch: [ 6/ 25], Step: [ 110/ 234], Loss: 0.4494\n",
            "Epoch: [ 6/ 25], Step: [ 120/ 234], Loss: 0.4852\n",
            "Epoch: [ 6/ 25], Step: [ 130/ 234], Loss: 0.4640\n",
            "Epoch: [ 6/ 25], Step: [ 140/ 234], Loss: 0.5683\n",
            "Epoch: [ 6/ 25], Step: [ 150/ 234], Loss: 0.4705\n",
            "Epoch: [ 6/ 25], Step: [ 160/ 234], Loss: 0.4036\n",
            "Epoch: [ 6/ 25], Step: [ 170/ 234], Loss: 0.5069\n",
            "Epoch: [ 6/ 25], Step: [ 180/ 234], Loss: 0.4895\n",
            "Epoch: [ 6/ 25], Step: [ 190/ 234], Loss: 0.4425\n",
            "Epoch: [ 6/ 25], Step: [ 200/ 234], Loss: 0.3609\n",
            "Epoch: [ 6/ 25], Step: [ 210/ 234], Loss: 0.4237\n",
            "Epoch: [ 6/ 25], Step: [ 220/ 234], Loss: 0.4317\n",
            "Epoch: [ 6/ 25], Step: [ 230/ 234], Loss: 0.5417\n",
            "Accuracy of the model on the 10000 test images: 84.9%\n",
            "Accuracy of the model on the 60000 train images: 84.4%\n",
            "Epoch: [ 7/ 25], Step: [ 10/ 234], Loss: 0.4644\n",
            "Epoch: [ 7/ 25], Step: [ 20/ 234], Loss: 0.3559\n",
            "Epoch: [ 7/ 25], Step: [ 30/ 234], Loss: 0.4577\n",
            "Epoch: [ 7/ 25], Step: [ 40/ 234], Loss: 0.5193\n",
            "Epoch: [ 7/ 25], Step: [ 50/ 234], Loss: 0.5926\n",
            "Epoch: [ 7/ 25], Step: [ 60/ 234], Loss: 0.4355\n",
            "Epoch: [ 7/ 25], Step: [ 70/ 234], Loss: 0.4697\n",
            "Epoch: [ 7/ 25], Step: [ 80/ 234], Loss: 0.6110\n",
            "Epoch: [ 7/ 25], Step: [ 90/ 234], Loss: 0.4518\n",
            "Epoch: [ 7/ 25], Step: [ 100/ 234], Loss: 0.4188\n",
            "Epoch: [ 7/ 25], Step: [ 110/ 234], Loss: 0.5354\n",
            "Epoch: [ 7/ 25], Step: [ 120/ 234], Loss: 0.4152\n",
            "Epoch: [ 7/ 25], Step: [ 130/ 234], Loss: 0.4960\n",
            "Epoch: [ 7/ 25], Step: [ 140/ 234], Loss: 0.4768\n",
            "Epoch: [ 7/ 25], Step: [ 150/ 234], Loss: 0.4922\n",
            "Epoch: [ 7/ 25], Step: [ 160/ 234], Loss: 0.4405\n",
            "Epoch: [ 7/ 25], Step: [ 170/ 234], Loss: 0.3450\n",
            "Epoch: [ 7/ 25], Step: [ 180/ 234], Loss: 0.4338\n",
            "Epoch: [ 7/ 25], Step: [ 190/ 234], Loss: 0.4918\n",
            "Epoch: [ 7/ 25], Step: [ 200/ 234], Loss: 0.4414\n",
            "Epoch: [ 7/ 25], Step: [ 210/ 234], Loss: 0.3889\n",
            "Epoch: [ 7/ 25], Step: [ 220/ 234], Loss: 0.5388\n",
            "Epoch: [ 7/ 25], Step: [ 230/ 234], Loss: 0.4837\n",
            "Accuracy of the model on the 10000 test images: 85.8%\n",
            "Accuracy of the model on the 60000 train images: 85.1%\n",
            "Epoch: [ 8/ 25], Step: [ 10/ 234], Loss: 0.5009\n",
            "Epoch: [ 8/ 25], Step: [ 20/ 234], Loss: 0.4090\n",
            "Epoch: [ 8/ 25], Step: [ 30/ 234], Loss: 0.5532\n",
            "Epoch: [ 8/ 25], Step: [ 40/ 234], Loss: 0.4127\n",
            "Epoch: [ 8/ 25], Step: [ 50/ 234], Loss: 0.4465\n",
            "Epoch: [ 8/ 25], Step: [ 60/ 234], Loss: 0.4079\n",
            "Epoch: [ 8/ 25], Step: [ 70/ 234], Loss: 0.6097\n",
            "Epoch: [ 8/ 25], Step: [ 80/ 234], Loss: 0.5247\n",
            "Epoch: [ 8/ 25], Step: [ 90/ 234], Loss: 0.4021\n",
            "Epoch: [ 8/ 25], Step: [ 100/ 234], Loss: 0.4668\n",
            "Epoch: [ 8/ 25], Step: [ 110/ 234], Loss: 0.3374\n",
            "Epoch: [ 8/ 25], Step: [ 120/ 234], Loss: 0.4431\n",
            "Epoch: [ 8/ 25], Step: [ 130/ 234], Loss: 0.3917\n",
            "Epoch: [ 8/ 25], Step: [ 140/ 234], Loss: 0.3398\n",
            "Epoch: [ 8/ 25], Step: [ 150/ 234], Loss: 0.6145\n",
            "Epoch: [ 8/ 25], Step: [ 160/ 234], Loss: 0.4183\n",
            "Epoch: [ 8/ 25], Step: [ 170/ 234], Loss: 0.3740\n",
            "Epoch: [ 8/ 25], Step: [ 180/ 234], Loss: 0.5284\n",
            "Epoch: [ 8/ 25], Step: [ 190/ 234], Loss: 0.3769\n",
            "Epoch: [ 8/ 25], Step: [ 200/ 234], Loss: 0.3984\n",
            "Epoch: [ 8/ 25], Step: [ 210/ 234], Loss: 0.4181\n",
            "Epoch: [ 8/ 25], Step: [ 220/ 234], Loss: 0.5746\n",
            "Epoch: [ 8/ 25], Step: [ 230/ 234], Loss: 0.5619\n",
            "Accuracy of the model on the 10000 test images: 86.3%\n",
            "Accuracy of the model on the 60000 train images: 85.7%\n",
            "Epoch: [ 9/ 25], Step: [ 10/ 234], Loss: 0.4862\n",
            "Epoch: [ 9/ 25], Step: [ 20/ 234], Loss: 0.5034\n",
            "Epoch: [ 9/ 25], Step: [ 30/ 234], Loss: 0.3773\n",
            "Epoch: [ 9/ 25], Step: [ 40/ 234], Loss: 0.5690\n",
            "Epoch: [ 9/ 25], Step: [ 50/ 234], Loss: 0.3116\n",
            "Epoch: [ 9/ 25], Step: [ 60/ 234], Loss: 0.4884\n",
            "Epoch: [ 9/ 25], Step: [ 70/ 234], Loss: 0.5876\n",
            "Epoch: [ 9/ 25], Step: [ 80/ 234], Loss: 0.5739\n",
            "Epoch: [ 9/ 25], Step: [ 90/ 234], Loss: 0.4746\n",
            "Epoch: [ 9/ 25], Step: [ 100/ 234], Loss: 0.4373\n",
            "Epoch: [ 9/ 25], Step: [ 110/ 234], Loss: 0.4464\n",
            "Epoch: [ 9/ 25], Step: [ 120/ 234], Loss: 0.4618\n",
            "Epoch: [ 9/ 25], Step: [ 130/ 234], Loss: 0.3750\n",
            "Epoch: [ 9/ 25], Step: [ 140/ 234], Loss: 0.3737\n",
            "Epoch: [ 9/ 25], Step: [ 150/ 234], Loss: 0.3901\n",
            "Epoch: [ 9/ 25], Step: [ 160/ 234], Loss: 0.4053\n",
            "Epoch: [ 9/ 25], Step: [ 170/ 234], Loss: 0.4425\n",
            "Epoch: [ 9/ 25], Step: [ 180/ 234], Loss: 0.3610\n",
            "Epoch: [ 9/ 25], Step: [ 190/ 234], Loss: 0.4151\n",
            "Epoch: [ 9/ 25], Step: [ 200/ 234], Loss: 0.5984\n",
            "Epoch: [ 9/ 25], Step: [ 210/ 234], Loss: 0.4187\n",
            "Epoch: [ 9/ 25], Step: [ 220/ 234], Loss: 0.3942\n",
            "Epoch: [ 9/ 25], Step: [ 230/ 234], Loss: 0.5634\n",
            "Accuracy of the model on the 10000 test images: 87.2%\n",
            "Accuracy of the model on the 60000 train images: 86.7%\n",
            "Epoch: [ 10/ 25], Step: [ 10/ 234], Loss: 0.4421\n",
            "Epoch: [ 10/ 25], Step: [ 20/ 234], Loss: 0.3245\n",
            "Epoch: [ 10/ 25], Step: [ 30/ 234], Loss: 0.4700\n",
            "Epoch: [ 10/ 25], Step: [ 40/ 234], Loss: 0.4549\n",
            "Epoch: [ 10/ 25], Step: [ 50/ 234], Loss: 0.4225\n",
            "Epoch: [ 10/ 25], Step: [ 60/ 234], Loss: 0.4863\n",
            "Epoch: [ 10/ 25], Step: [ 70/ 234], Loss: 0.5146\n",
            "Epoch: [ 10/ 25], Step: [ 80/ 234], Loss: 0.4802\n",
            "Epoch: [ 10/ 25], Step: [ 90/ 234], Loss: 0.4208\n",
            "Epoch: [ 10/ 25], Step: [ 100/ 234], Loss: 0.4862\n",
            "Epoch: [ 10/ 25], Step: [ 110/ 234], Loss: 0.3925\n",
            "Epoch: [ 10/ 25], Step: [ 120/ 234], Loss: 0.5150\n",
            "Epoch: [ 10/ 25], Step: [ 130/ 234], Loss: 0.3509\n",
            "Epoch: [ 10/ 25], Step: [ 140/ 234], Loss: 0.3201\n",
            "Epoch: [ 10/ 25], Step: [ 150/ 234], Loss: 0.4186\n",
            "Epoch: [ 10/ 25], Step: [ 160/ 234], Loss: 0.3760\n",
            "Epoch: [ 10/ 25], Step: [ 170/ 234], Loss: 0.5059\n",
            "Epoch: [ 10/ 25], Step: [ 180/ 234], Loss: 0.3810\n",
            "Epoch: [ 10/ 25], Step: [ 190/ 234], Loss: 0.4581\n",
            "Epoch: [ 10/ 25], Step: [ 200/ 234], Loss: 0.3854\n",
            "Epoch: [ 10/ 25], Step: [ 210/ 234], Loss: 0.4022\n",
            "Epoch: [ 10/ 25], Step: [ 220/ 234], Loss: 0.3953\n",
            "Epoch: [ 10/ 25], Step: [ 230/ 234], Loss: 0.4782\n",
            "Accuracy of the model on the 10000 test images: 87.5%\n",
            "Accuracy of the model on the 60000 train images: 87.0%\n",
            "Epoch: [ 11/ 25], Step: [ 10/ 234], Loss: 0.4743\n",
            "Epoch: [ 11/ 25], Step: [ 20/ 234], Loss: 0.5928\n",
            "Epoch: [ 11/ 25], Step: [ 30/ 234], Loss: 0.3975\n",
            "Epoch: [ 11/ 25], Step: [ 40/ 234], Loss: 0.4136\n",
            "Epoch: [ 11/ 25], Step: [ 50/ 234], Loss: 0.4921\n",
            "Epoch: [ 11/ 25], Step: [ 60/ 234], Loss: 0.3669\n",
            "Epoch: [ 11/ 25], Step: [ 70/ 234], Loss: 0.4579\n",
            "Epoch: [ 11/ 25], Step: [ 80/ 234], Loss: 0.3107\n",
            "Epoch: [ 11/ 25], Step: [ 90/ 234], Loss: 0.3757\n",
            "Epoch: [ 11/ 25], Step: [ 100/ 234], Loss: 0.3324\n",
            "Epoch: [ 11/ 25], Step: [ 110/ 234], Loss: 0.4258\n",
            "Epoch: [ 11/ 25], Step: [ 120/ 234], Loss: 0.3391\n",
            "Epoch: [ 11/ 25], Step: [ 130/ 234], Loss: 0.4412\n",
            "Epoch: [ 11/ 25], Step: [ 140/ 234], Loss: 0.3375\n",
            "Epoch: [ 11/ 25], Step: [ 150/ 234], Loss: 0.3303\n",
            "Epoch: [ 11/ 25], Step: [ 160/ 234], Loss: 0.4781\n",
            "Epoch: [ 11/ 25], Step: [ 170/ 234], Loss: 0.4253\n",
            "Epoch: [ 11/ 25], Step: [ 180/ 234], Loss: 0.4123\n",
            "Epoch: [ 11/ 25], Step: [ 190/ 234], Loss: 0.3702\n",
            "Epoch: [ 11/ 25], Step: [ 200/ 234], Loss: 0.3683\n",
            "Epoch: [ 11/ 25], Step: [ 210/ 234], Loss: 0.4993\n",
            "Epoch: [ 11/ 25], Step: [ 220/ 234], Loss: 0.3425\n",
            "Epoch: [ 11/ 25], Step: [ 230/ 234], Loss: 0.3937\n",
            "Accuracy of the model on the 10000 test images: 88.1%\n",
            "Accuracy of the model on the 60000 train images: 87.5%\n",
            "Epoch: [ 12/ 25], Step: [ 10/ 234], Loss: 0.3437\n",
            "Epoch: [ 12/ 25], Step: [ 20/ 234], Loss: 0.4919\n",
            "Epoch: [ 12/ 25], Step: [ 30/ 234], Loss: 0.4508\n",
            "Epoch: [ 12/ 25], Step: [ 40/ 234], Loss: 0.3387\n",
            "Epoch: [ 12/ 25], Step: [ 50/ 234], Loss: 0.3930\n",
            "Epoch: [ 12/ 25], Step: [ 60/ 234], Loss: 0.4707\n",
            "Epoch: [ 12/ 25], Step: [ 70/ 234], Loss: 0.4688\n",
            "Epoch: [ 12/ 25], Step: [ 80/ 234], Loss: 0.4470\n",
            "Epoch: [ 12/ 25], Step: [ 90/ 234], Loss: 0.4673\n",
            "Epoch: [ 12/ 25], Step: [ 100/ 234], Loss: 0.3423\n",
            "Epoch: [ 12/ 25], Step: [ 110/ 234], Loss: 0.4351\n",
            "Epoch: [ 12/ 25], Step: [ 120/ 234], Loss: 0.3551\n",
            "Epoch: [ 12/ 25], Step: [ 130/ 234], Loss: 0.3378\n",
            "Epoch: [ 12/ 25], Step: [ 140/ 234], Loss: 0.3744\n",
            "Epoch: [ 12/ 25], Step: [ 150/ 234], Loss: 0.4091\n",
            "Epoch: [ 12/ 25], Step: [ 160/ 234], Loss: 0.3961\n",
            "Epoch: [ 12/ 25], Step: [ 170/ 234], Loss: 0.4051\n",
            "Epoch: [ 12/ 25], Step: [ 180/ 234], Loss: 0.3959\n",
            "Epoch: [ 12/ 25], Step: [ 190/ 234], Loss: 0.4248\n",
            "Epoch: [ 12/ 25], Step: [ 200/ 234], Loss: 0.3311\n",
            "Epoch: [ 12/ 25], Step: [ 210/ 234], Loss: 0.3690\n",
            "Epoch: [ 12/ 25], Step: [ 220/ 234], Loss: 0.3834\n",
            "Epoch: [ 12/ 25], Step: [ 230/ 234], Loss: 0.3785\n",
            "Accuracy of the model on the 10000 test images: 88.0%\n",
            "Accuracy of the model on the 60000 train images: 87.7%\n",
            "Epoch: [ 13/ 25], Step: [ 10/ 234], Loss: 0.5282\n",
            "Epoch: [ 13/ 25], Step: [ 20/ 234], Loss: 0.5024\n",
            "Epoch: [ 13/ 25], Step: [ 30/ 234], Loss: 0.4041\n",
            "Epoch: [ 13/ 25], Step: [ 40/ 234], Loss: 0.3465\n",
            "Epoch: [ 13/ 25], Step: [ 50/ 234], Loss: 0.3419\n",
            "Epoch: [ 13/ 25], Step: [ 60/ 234], Loss: 0.3738\n",
            "Epoch: [ 13/ 25], Step: [ 70/ 234], Loss: 0.3457\n",
            "Epoch: [ 13/ 25], Step: [ 80/ 234], Loss: 0.3636\n",
            "Epoch: [ 13/ 25], Step: [ 90/ 234], Loss: 0.3765\n",
            "Epoch: [ 13/ 25], Step: [ 100/ 234], Loss: 0.4710\n",
            "Epoch: [ 13/ 25], Step: [ 110/ 234], Loss: 0.3864\n",
            "Epoch: [ 13/ 25], Step: [ 120/ 234], Loss: 0.3139\n",
            "Epoch: [ 13/ 25], Step: [ 130/ 234], Loss: 0.2725\n",
            "Epoch: [ 13/ 25], Step: [ 140/ 234], Loss: 0.3291\n",
            "Epoch: [ 13/ 25], Step: [ 150/ 234], Loss: 0.3401\n",
            "Epoch: [ 13/ 25], Step: [ 160/ 234], Loss: 0.3957\n",
            "Epoch: [ 13/ 25], Step: [ 170/ 234], Loss: 0.3273\n",
            "Epoch: [ 13/ 25], Step: [ 180/ 234], Loss: 0.3950\n",
            "Epoch: [ 13/ 25], Step: [ 190/ 234], Loss: 0.3685\n",
            "Epoch: [ 13/ 25], Step: [ 200/ 234], Loss: 0.4396\n",
            "Epoch: [ 13/ 25], Step: [ 210/ 234], Loss: 0.4748\n",
            "Epoch: [ 13/ 25], Step: [ 220/ 234], Loss: 0.4259\n",
            "Epoch: [ 13/ 25], Step: [ 230/ 234], Loss: 0.3576\n",
            "Accuracy of the model on the 10000 test images: 88.5%\n",
            "Accuracy of the model on the 60000 train images: 88.0%\n",
            "Epoch: [ 14/ 25], Step: [ 10/ 234], Loss: 0.3621\n",
            "Epoch: [ 14/ 25], Step: [ 20/ 234], Loss: 0.3640\n",
            "Epoch: [ 14/ 25], Step: [ 30/ 234], Loss: 0.3891\n",
            "Epoch: [ 14/ 25], Step: [ 40/ 234], Loss: 0.3388\n",
            "Epoch: [ 14/ 25], Step: [ 50/ 234], Loss: 0.3354\n",
            "Epoch: [ 14/ 25], Step: [ 60/ 234], Loss: 0.3073\n",
            "Epoch: [ 14/ 25], Step: [ 70/ 234], Loss: 0.4556\n",
            "Epoch: [ 14/ 25], Step: [ 80/ 234], Loss: 0.3091\n",
            "Epoch: [ 14/ 25], Step: [ 90/ 234], Loss: 0.4450\n",
            "Epoch: [ 14/ 25], Step: [ 100/ 234], Loss: 0.3419\n",
            "Epoch: [ 14/ 25], Step: [ 110/ 234], Loss: 0.3486\n",
            "Epoch: [ 14/ 25], Step: [ 120/ 234], Loss: 0.3562\n",
            "Epoch: [ 14/ 25], Step: [ 130/ 234], Loss: 0.3779\n",
            "Epoch: [ 14/ 25], Step: [ 140/ 234], Loss: 0.3981\n",
            "Epoch: [ 14/ 25], Step: [ 150/ 234], Loss: 0.3953\n",
            "Epoch: [ 14/ 25], Step: [ 160/ 234], Loss: 0.3108\n",
            "Epoch: [ 14/ 25], Step: [ 170/ 234], Loss: 0.4325\n",
            "Epoch: [ 14/ 25], Step: [ 180/ 234], Loss: 0.3063\n",
            "Epoch: [ 14/ 25], Step: [ 190/ 234], Loss: 0.3089\n",
            "Epoch: [ 14/ 25], Step: [ 200/ 234], Loss: 0.3342\n",
            "Epoch: [ 14/ 25], Step: [ 210/ 234], Loss: 0.4239\n",
            "Epoch: [ 14/ 25], Step: [ 220/ 234], Loss: 0.3606\n",
            "Epoch: [ 14/ 25], Step: [ 230/ 234], Loss: 0.3295\n",
            "Accuracy of the model on the 10000 test images: 89.2%\n",
            "Accuracy of the model on the 60000 train images: 88.8%\n",
            "Epoch: [ 15/ 25], Step: [ 10/ 234], Loss: 0.3642\n",
            "Epoch: [ 15/ 25], Step: [ 20/ 234], Loss: 0.3431\n",
            "Epoch: [ 15/ 25], Step: [ 30/ 234], Loss: 0.3186\n",
            "Epoch: [ 15/ 25], Step: [ 40/ 234], Loss: 0.3919\n",
            "Epoch: [ 15/ 25], Step: [ 50/ 234], Loss: 0.3121\n",
            "Epoch: [ 15/ 25], Step: [ 60/ 234], Loss: 0.4077\n",
            "Epoch: [ 15/ 25], Step: [ 70/ 234], Loss: 0.3916\n",
            "Epoch: [ 15/ 25], Step: [ 80/ 234], Loss: 0.5390\n",
            "Epoch: [ 15/ 25], Step: [ 90/ 234], Loss: 0.3884\n",
            "Epoch: [ 15/ 25], Step: [ 100/ 234], Loss: 0.4064\n",
            "Epoch: [ 15/ 25], Step: [ 110/ 234], Loss: 0.3791\n",
            "Epoch: [ 15/ 25], Step: [ 120/ 234], Loss: 0.4439\n",
            "Epoch: [ 15/ 25], Step: [ 130/ 234], Loss: 0.3371\n",
            "Epoch: [ 15/ 25], Step: [ 140/ 234], Loss: 0.3694\n",
            "Epoch: [ 15/ 25], Step: [ 150/ 234], Loss: 0.2999\n",
            "Epoch: [ 15/ 25], Step: [ 160/ 234], Loss: 0.3043\n",
            "Epoch: [ 15/ 25], Step: [ 170/ 234], Loss: 0.3745\n",
            "Epoch: [ 15/ 25], Step: [ 180/ 234], Loss: 0.4024\n",
            "Epoch: [ 15/ 25], Step: [ 190/ 234], Loss: 0.3042\n",
            "Epoch: [ 15/ 25], Step: [ 200/ 234], Loss: 0.4022\n",
            "Epoch: [ 15/ 25], Step: [ 210/ 234], Loss: 0.2158\n",
            "Epoch: [ 15/ 25], Step: [ 220/ 234], Loss: 0.2402\n",
            "Epoch: [ 15/ 25], Step: [ 230/ 234], Loss: 0.3375\n",
            "Accuracy of the model on the 10000 test images: 89.3%\n",
            "Accuracy of the model on the 60000 train images: 89.0%\n",
            "Epoch: [ 16/ 25], Step: [ 10/ 234], Loss: 0.4307\n",
            "Epoch: [ 16/ 25], Step: [ 20/ 234], Loss: 0.3445\n",
            "Epoch: [ 16/ 25], Step: [ 30/ 234], Loss: 0.3825\n",
            "Epoch: [ 16/ 25], Step: [ 40/ 234], Loss: 0.3086\n",
            "Epoch: [ 16/ 25], Step: [ 50/ 234], Loss: 0.3559\n",
            "Epoch: [ 16/ 25], Step: [ 60/ 234], Loss: 0.3682\n",
            "Epoch: [ 16/ 25], Step: [ 70/ 234], Loss: 0.3900\n",
            "Epoch: [ 16/ 25], Step: [ 80/ 234], Loss: 0.3594\n",
            "Epoch: [ 16/ 25], Step: [ 90/ 234], Loss: 0.4456\n",
            "Epoch: [ 16/ 25], Step: [ 100/ 234], Loss: 0.3119\n",
            "Epoch: [ 16/ 25], Step: [ 110/ 234], Loss: 0.3853\n",
            "Epoch: [ 16/ 25], Step: [ 120/ 234], Loss: 0.2669\n",
            "Epoch: [ 16/ 25], Step: [ 130/ 234], Loss: 0.3170\n",
            "Epoch: [ 16/ 25], Step: [ 140/ 234], Loss: 0.3688\n",
            "Epoch: [ 16/ 25], Step: [ 150/ 234], Loss: 0.2946\n",
            "Epoch: [ 16/ 25], Step: [ 160/ 234], Loss: 0.4197\n",
            "Epoch: [ 16/ 25], Step: [ 170/ 234], Loss: 0.3322\n",
            "Epoch: [ 16/ 25], Step: [ 180/ 234], Loss: 0.3954\n",
            "Epoch: [ 16/ 25], Step: [ 190/ 234], Loss: 0.3629\n",
            "Epoch: [ 16/ 25], Step: [ 200/ 234], Loss: 0.4639\n",
            "Epoch: [ 16/ 25], Step: [ 210/ 234], Loss: 0.3761\n",
            "Epoch: [ 16/ 25], Step: [ 220/ 234], Loss: 0.3667\n",
            "Epoch: [ 16/ 25], Step: [ 230/ 234], Loss: 0.3567\n",
            "Accuracy of the model on the 10000 test images: 89.6%\n",
            "Accuracy of the model on the 60000 train images: 89.1%\n",
            "Epoch: [ 17/ 25], Step: [ 10/ 234], Loss: 0.3386\n",
            "Epoch: [ 17/ 25], Step: [ 20/ 234], Loss: 0.4597\n",
            "Epoch: [ 17/ 25], Step: [ 30/ 234], Loss: 0.3581\n",
            "Epoch: [ 17/ 25], Step: [ 40/ 234], Loss: 0.3880\n",
            "Epoch: [ 17/ 25], Step: [ 50/ 234], Loss: 0.4106\n",
            "Epoch: [ 17/ 25], Step: [ 60/ 234], Loss: 0.4154\n",
            "Epoch: [ 17/ 25], Step: [ 70/ 234], Loss: 0.3949\n",
            "Epoch: [ 17/ 25], Step: [ 80/ 234], Loss: 0.4761\n",
            "Epoch: [ 17/ 25], Step: [ 90/ 234], Loss: 0.2751\n",
            "Epoch: [ 17/ 25], Step: [ 100/ 234], Loss: 0.3731\n",
            "Epoch: [ 17/ 25], Step: [ 110/ 234], Loss: 0.4709\n",
            "Epoch: [ 17/ 25], Step: [ 120/ 234], Loss: 0.4262\n",
            "Epoch: [ 17/ 25], Step: [ 130/ 234], Loss: 0.3178\n",
            "Epoch: [ 17/ 25], Step: [ 140/ 234], Loss: 0.2796\n",
            "Epoch: [ 17/ 25], Step: [ 150/ 234], Loss: 0.3128\n",
            "Epoch: [ 17/ 25], Step: [ 160/ 234], Loss: 0.3518\n",
            "Epoch: [ 17/ 25], Step: [ 170/ 234], Loss: 0.3268\n",
            "Epoch: [ 17/ 25], Step: [ 180/ 234], Loss: 0.3329\n",
            "Epoch: [ 17/ 25], Step: [ 190/ 234], Loss: 0.3968\n",
            "Epoch: [ 17/ 25], Step: [ 200/ 234], Loss: 0.3383\n",
            "Epoch: [ 17/ 25], Step: [ 210/ 234], Loss: 0.3951\n",
            "Epoch: [ 17/ 25], Step: [ 220/ 234], Loss: 0.3438\n",
            "Epoch: [ 17/ 25], Step: [ 230/ 234], Loss: 0.3852\n",
            "Accuracy of the model on the 10000 test images: 89.7%\n",
            "Accuracy of the model on the 60000 train images: 89.3%\n",
            "Epoch: [ 18/ 25], Step: [ 10/ 234], Loss: 0.3132\n",
            "Epoch: [ 18/ 25], Step: [ 20/ 234], Loss: 0.3586\n",
            "Epoch: [ 18/ 25], Step: [ 30/ 234], Loss: 0.3380\n",
            "Epoch: [ 18/ 25], Step: [ 40/ 234], Loss: 0.3635\n",
            "Epoch: [ 18/ 25], Step: [ 50/ 234], Loss: 0.3904\n",
            "Epoch: [ 18/ 25], Step: [ 60/ 234], Loss: 0.3515\n",
            "Epoch: [ 18/ 25], Step: [ 70/ 234], Loss: 0.3537\n",
            "Epoch: [ 18/ 25], Step: [ 80/ 234], Loss: 0.3762\n",
            "Epoch: [ 18/ 25], Step: [ 90/ 234], Loss: 0.3253\n",
            "Epoch: [ 18/ 25], Step: [ 100/ 234], Loss: 0.3436\n",
            "Epoch: [ 18/ 25], Step: [ 110/ 234], Loss: 0.3103\n",
            "Epoch: [ 18/ 25], Step: [ 120/ 234], Loss: 0.3503\n",
            "Epoch: [ 18/ 25], Step: [ 130/ 234], Loss: 0.2812\n",
            "Epoch: [ 18/ 25], Step: [ 140/ 234], Loss: 0.3833\n",
            "Epoch: [ 18/ 25], Step: [ 150/ 234], Loss: 0.2879\n",
            "Epoch: [ 18/ 25], Step: [ 160/ 234], Loss: 0.4239\n",
            "Epoch: [ 18/ 25], Step: [ 170/ 234], Loss: 0.3982\n",
            "Epoch: [ 18/ 25], Step: [ 180/ 234], Loss: 0.3872\n",
            "Epoch: [ 18/ 25], Step: [ 190/ 234], Loss: 0.3325\n",
            "Epoch: [ 18/ 25], Step: [ 200/ 234], Loss: 0.3385\n",
            "Epoch: [ 18/ 25], Step: [ 210/ 234], Loss: 0.4017\n",
            "Epoch: [ 18/ 25], Step: [ 220/ 234], Loss: 0.3982\n",
            "Epoch: [ 18/ 25], Step: [ 230/ 234], Loss: 0.3471\n",
            "Accuracy of the model on the 10000 test images: 90.0%\n",
            "Accuracy of the model on the 60000 train images: 89.4%\n",
            "Epoch: [ 19/ 25], Step: [ 10/ 234], Loss: 0.3209\n",
            "Epoch: [ 19/ 25], Step: [ 20/ 234], Loss: 0.2817\n",
            "Epoch: [ 19/ 25], Step: [ 30/ 234], Loss: 0.3145\n",
            "Epoch: [ 19/ 25], Step: [ 40/ 234], Loss: 0.3895\n",
            "Epoch: [ 19/ 25], Step: [ 50/ 234], Loss: 0.4463\n",
            "Epoch: [ 19/ 25], Step: [ 60/ 234], Loss: 0.2565\n",
            "Epoch: [ 19/ 25], Step: [ 70/ 234], Loss: 0.3221\n",
            "Epoch: [ 19/ 25], Step: [ 80/ 234], Loss: 0.2916\n",
            "Epoch: [ 19/ 25], Step: [ 90/ 234], Loss: 0.3932\n",
            "Epoch: [ 19/ 25], Step: [ 100/ 234], Loss: 0.2648\n",
            "Epoch: [ 19/ 25], Step: [ 110/ 234], Loss: 0.3179\n",
            "Epoch: [ 19/ 25], Step: [ 120/ 234], Loss: 0.3470\n",
            "Epoch: [ 19/ 25], Step: [ 130/ 234], Loss: 0.3986\n",
            "Epoch: [ 19/ 25], Step: [ 140/ 234], Loss: 0.3899\n",
            "Epoch: [ 19/ 25], Step: [ 150/ 234], Loss: 0.3334\n",
            "Epoch: [ 19/ 25], Step: [ 160/ 234], Loss: 0.3323\n",
            "Epoch: [ 19/ 25], Step: [ 170/ 234], Loss: 0.3289\n",
            "Epoch: [ 19/ 25], Step: [ 180/ 234], Loss: 0.3398\n",
            "Epoch: [ 19/ 25], Step: [ 190/ 234], Loss: 0.3506\n",
            "Epoch: [ 19/ 25], Step: [ 200/ 234], Loss: 0.3212\n",
            "Epoch: [ 19/ 25], Step: [ 210/ 234], Loss: 0.3095\n",
            "Epoch: [ 19/ 25], Step: [ 220/ 234], Loss: 0.3085\n",
            "Epoch: [ 19/ 25], Step: [ 230/ 234], Loss: 0.3262\n",
            "Accuracy of the model on the 10000 test images: 89.8%\n",
            "Accuracy of the model on the 60000 train images: 89.5%\n",
            "Epoch: [ 20/ 25], Step: [ 10/ 234], Loss: 0.3259\n",
            "Epoch: [ 20/ 25], Step: [ 20/ 234], Loss: 0.2528\n",
            "Epoch: [ 20/ 25], Step: [ 30/ 234], Loss: 0.3145\n",
            "Epoch: [ 20/ 25], Step: [ 40/ 234], Loss: 0.4212\n",
            "Epoch: [ 20/ 25], Step: [ 50/ 234], Loss: 0.3503\n",
            "Epoch: [ 20/ 25], Step: [ 60/ 234], Loss: 0.3301\n",
            "Epoch: [ 20/ 25], Step: [ 70/ 234], Loss: 0.4579\n",
            "Epoch: [ 20/ 25], Step: [ 80/ 234], Loss: 0.4487\n",
            "Epoch: [ 20/ 25], Step: [ 90/ 234], Loss: 0.2814\n",
            "Epoch: [ 20/ 25], Step: [ 100/ 234], Loss: 0.3152\n",
            "Epoch: [ 20/ 25], Step: [ 110/ 234], Loss: 0.4018\n",
            "Epoch: [ 20/ 25], Step: [ 120/ 234], Loss: 0.3068\n",
            "Epoch: [ 20/ 25], Step: [ 130/ 234], Loss: 0.3026\n",
            "Epoch: [ 20/ 25], Step: [ 140/ 234], Loss: 0.3769\n",
            "Epoch: [ 20/ 25], Step: [ 150/ 234], Loss: 0.2235\n",
            "Epoch: [ 20/ 25], Step: [ 160/ 234], Loss: 0.4006\n",
            "Epoch: [ 20/ 25], Step: [ 170/ 234], Loss: 0.3907\n",
            "Epoch: [ 20/ 25], Step: [ 180/ 234], Loss: 0.2453\n",
            "Epoch: [ 20/ 25], Step: [ 190/ 234], Loss: 0.4133\n",
            "Epoch: [ 20/ 25], Step: [ 200/ 234], Loss: 0.3107\n",
            "Epoch: [ 20/ 25], Step: [ 210/ 234], Loss: 0.3958\n",
            "Epoch: [ 20/ 25], Step: [ 220/ 234], Loss: 0.3064\n",
            "Epoch: [ 20/ 25], Step: [ 230/ 234], Loss: 0.4241\n",
            "Accuracy of the model on the 10000 test images: 89.7%\n",
            "Accuracy of the model on the 60000 train images: 89.4%\n",
            "Epoch: [ 21/ 25], Step: [ 10/ 234], Loss: 0.3413\n",
            "Epoch: [ 21/ 25], Step: [ 20/ 234], Loss: 0.3074\n",
            "Epoch: [ 21/ 25], Step: [ 30/ 234], Loss: 0.2665\n",
            "Epoch: [ 21/ 25], Step: [ 40/ 234], Loss: 0.2666\n",
            "Epoch: [ 21/ 25], Step: [ 50/ 234], Loss: 0.3002\n",
            "Epoch: [ 21/ 25], Step: [ 60/ 234], Loss: 0.3620\n",
            "Epoch: [ 21/ 25], Step: [ 70/ 234], Loss: 0.4416\n",
            "Epoch: [ 21/ 25], Step: [ 80/ 234], Loss: 0.4902\n",
            "Epoch: [ 21/ 25], Step: [ 90/ 234], Loss: 0.3783\n",
            "Epoch: [ 21/ 25], Step: [ 100/ 234], Loss: 0.3095\n",
            "Epoch: [ 21/ 25], Step: [ 110/ 234], Loss: 0.2667\n",
            "Epoch: [ 21/ 25], Step: [ 120/ 234], Loss: 0.4136\n",
            "Epoch: [ 21/ 25], Step: [ 130/ 234], Loss: 0.3438\n",
            "Epoch: [ 21/ 25], Step: [ 140/ 234], Loss: 0.4170\n",
            "Epoch: [ 21/ 25], Step: [ 150/ 234], Loss: 0.2507\n",
            "Epoch: [ 21/ 25], Step: [ 160/ 234], Loss: 0.3092\n",
            "Epoch: [ 21/ 25], Step: [ 170/ 234], Loss: 0.4611\n",
            "Epoch: [ 21/ 25], Step: [ 180/ 234], Loss: 0.2263\n",
            "Epoch: [ 21/ 25], Step: [ 190/ 234], Loss: 0.4209\n",
            "Epoch: [ 21/ 25], Step: [ 200/ 234], Loss: 0.2209\n",
            "Epoch: [ 21/ 25], Step: [ 210/ 234], Loss: 0.3491\n",
            "Epoch: [ 21/ 25], Step: [ 220/ 234], Loss: 0.2659\n",
            "Epoch: [ 21/ 25], Step: [ 230/ 234], Loss: 0.2724\n",
            "Accuracy of the model on the 10000 test images: 90.6%\n",
            "Accuracy of the model on the 60000 train images: 90.0%\n",
            "Epoch: [ 22/ 25], Step: [ 10/ 234], Loss: 0.3144\n",
            "Epoch: [ 22/ 25], Step: [ 20/ 234], Loss: 0.4768\n",
            "Epoch: [ 22/ 25], Step: [ 30/ 234], Loss: 0.2900\n",
            "Epoch: [ 22/ 25], Step: [ 40/ 234], Loss: 0.4069\n",
            "Epoch: [ 22/ 25], Step: [ 50/ 234], Loss: 0.4123\n",
            "Epoch: [ 22/ 25], Step: [ 60/ 234], Loss: 0.2232\n",
            "Epoch: [ 22/ 25], Step: [ 70/ 234], Loss: 0.2673\n",
            "Epoch: [ 22/ 25], Step: [ 80/ 234], Loss: 0.3461\n",
            "Epoch: [ 22/ 25], Step: [ 90/ 234], Loss: 0.2898\n",
            "Epoch: [ 22/ 25], Step: [ 100/ 234], Loss: 0.3173\n",
            "Epoch: [ 22/ 25], Step: [ 110/ 234], Loss: 0.3783\n",
            "Epoch: [ 22/ 25], Step: [ 120/ 234], Loss: 0.2768\n",
            "Epoch: [ 22/ 25], Step: [ 130/ 234], Loss: 0.3381\n",
            "Epoch: [ 22/ 25], Step: [ 140/ 234], Loss: 0.4433\n",
            "Epoch: [ 22/ 25], Step: [ 150/ 234], Loss: 0.3319\n",
            "Epoch: [ 22/ 25], Step: [ 160/ 234], Loss: 0.3173\n",
            "Epoch: [ 22/ 25], Step: [ 170/ 234], Loss: 0.4070\n",
            "Epoch: [ 22/ 25], Step: [ 180/ 234], Loss: 0.2741\n",
            "Epoch: [ 22/ 25], Step: [ 190/ 234], Loss: 0.3681\n",
            "Epoch: [ 22/ 25], Step: [ 200/ 234], Loss: 0.2657\n",
            "Epoch: [ 22/ 25], Step: [ 210/ 234], Loss: 0.3257\n",
            "Epoch: [ 22/ 25], Step: [ 220/ 234], Loss: 0.2782\n",
            "Epoch: [ 22/ 25], Step: [ 230/ 234], Loss: 0.3467\n",
            "Accuracy of the model on the 10000 test images: 90.5%\n",
            "Accuracy of the model on the 60000 train images: 90.0%\n",
            "Epoch: [ 23/ 25], Step: [ 10/ 234], Loss: 0.3290\n",
            "Epoch: [ 23/ 25], Step: [ 20/ 234], Loss: 0.3023\n",
            "Epoch: [ 23/ 25], Step: [ 30/ 234], Loss: 0.3814\n",
            "Epoch: [ 23/ 25], Step: [ 40/ 234], Loss: 0.2973\n",
            "Epoch: [ 23/ 25], Step: [ 50/ 234], Loss: 0.3277\n",
            "Epoch: [ 23/ 25], Step: [ 60/ 234], Loss: 0.3233\n",
            "Epoch: [ 23/ 25], Step: [ 70/ 234], Loss: 0.3486\n",
            "Epoch: [ 23/ 25], Step: [ 80/ 234], Loss: 0.3768\n",
            "Epoch: [ 23/ 25], Step: [ 90/ 234], Loss: 0.3217\n",
            "Epoch: [ 23/ 25], Step: [ 100/ 234], Loss: 0.2700\n",
            "Epoch: [ 23/ 25], Step: [ 110/ 234], Loss: 0.4311\n",
            "Epoch: [ 23/ 25], Step: [ 120/ 234], Loss: 0.4132\n",
            "Epoch: [ 23/ 25], Step: [ 130/ 234], Loss: 0.3639\n",
            "Epoch: [ 23/ 25], Step: [ 140/ 234], Loss: 0.2780\n",
            "Epoch: [ 23/ 25], Step: [ 150/ 234], Loss: 0.2714\n",
            "Epoch: [ 23/ 25], Step: [ 160/ 234], Loss: 0.2906\n",
            "Epoch: [ 23/ 25], Step: [ 170/ 234], Loss: 0.2721\n",
            "Epoch: [ 23/ 25], Step: [ 180/ 234], Loss: 0.3900\n",
            "Epoch: [ 23/ 25], Step: [ 190/ 234], Loss: 0.2681\n",
            "Epoch: [ 23/ 25], Step: [ 200/ 234], Loss: 0.3721\n",
            "Epoch: [ 23/ 25], Step: [ 210/ 234], Loss: 0.3024\n",
            "Epoch: [ 23/ 25], Step: [ 220/ 234], Loss: 0.3512\n",
            "Epoch: [ 23/ 25], Step: [ 230/ 234], Loss: 0.3990\n",
            "Accuracy of the model on the 10000 test images: 90.6%\n",
            "Accuracy of the model on the 60000 train images: 90.5%\n",
            "Epoch: [ 24/ 25], Step: [ 10/ 234], Loss: 0.2985\n",
            "Epoch: [ 24/ 25], Step: [ 20/ 234], Loss: 0.2987\n",
            "Epoch: [ 24/ 25], Step: [ 30/ 234], Loss: 0.3017\n",
            "Epoch: [ 24/ 25], Step: [ 40/ 234], Loss: 0.3112\n",
            "Epoch: [ 24/ 25], Step: [ 50/ 234], Loss: 0.3478\n",
            "Epoch: [ 24/ 25], Step: [ 60/ 234], Loss: 0.3064\n",
            "Epoch: [ 24/ 25], Step: [ 70/ 234], Loss: 0.4567\n",
            "Epoch: [ 24/ 25], Step: [ 80/ 234], Loss: 0.3128\n",
            "Epoch: [ 24/ 25], Step: [ 90/ 234], Loss: 0.3722\n",
            "Epoch: [ 24/ 25], Step: [ 100/ 234], Loss: 0.3221\n",
            "Epoch: [ 24/ 25], Step: [ 110/ 234], Loss: 0.3060\n",
            "Epoch: [ 24/ 25], Step: [ 120/ 234], Loss: 0.2310\n",
            "Epoch: [ 24/ 25], Step: [ 130/ 234], Loss: 0.2830\n",
            "Epoch: [ 24/ 25], Step: [ 140/ 234], Loss: 0.2971\n",
            "Epoch: [ 24/ 25], Step: [ 150/ 234], Loss: 0.3710\n",
            "Epoch: [ 24/ 25], Step: [ 160/ 234], Loss: 0.2975\n",
            "Epoch: [ 24/ 25], Step: [ 170/ 234], Loss: 0.2951\n",
            "Epoch: [ 24/ 25], Step: [ 180/ 234], Loss: 0.3240\n",
            "Epoch: [ 24/ 25], Step: [ 190/ 234], Loss: 0.3223\n",
            "Epoch: [ 24/ 25], Step: [ 200/ 234], Loss: 0.3147\n",
            "Epoch: [ 24/ 25], Step: [ 210/ 234], Loss: 0.2867\n",
            "Epoch: [ 24/ 25], Step: [ 220/ 234], Loss: 0.3527\n",
            "Epoch: [ 24/ 25], Step: [ 230/ 234], Loss: 0.3122\n",
            "Accuracy of the model on the 10000 test images: 90.8%\n",
            "Accuracy of the model on the 60000 train images: 90.5%\n",
            "Epoch: [ 25/ 25], Step: [ 10/ 234], Loss: 0.3481\n",
            "Epoch: [ 25/ 25], Step: [ 20/ 234], Loss: 0.3969\n",
            "Epoch: [ 25/ 25], Step: [ 30/ 234], Loss: 0.3870\n",
            "Epoch: [ 25/ 25], Step: [ 40/ 234], Loss: 0.3419\n",
            "Epoch: [ 25/ 25], Step: [ 50/ 234], Loss: 0.3836\n",
            "Epoch: [ 25/ 25], Step: [ 60/ 234], Loss: 0.3151\n",
            "Epoch: [ 25/ 25], Step: [ 70/ 234], Loss: 0.2569\n",
            "Epoch: [ 25/ 25], Step: [ 80/ 234], Loss: 0.3064\n",
            "Epoch: [ 25/ 25], Step: [ 90/ 234], Loss: 0.2614\n",
            "Epoch: [ 25/ 25], Step: [ 100/ 234], Loss: 0.3026\n",
            "Epoch: [ 25/ 25], Step: [ 110/ 234], Loss: 0.2871\n",
            "Epoch: [ 25/ 25], Step: [ 120/ 234], Loss: 0.2778\n",
            "Epoch: [ 25/ 25], Step: [ 130/ 234], Loss: 0.2870\n",
            "Epoch: [ 25/ 25], Step: [ 140/ 234], Loss: 0.2509\n",
            "Epoch: [ 25/ 25], Step: [ 150/ 234], Loss: 0.3664\n",
            "Epoch: [ 25/ 25], Step: [ 160/ 234], Loss: 0.3655\n",
            "Epoch: [ 25/ 25], Step: [ 170/ 234], Loss: 0.2898\n",
            "Epoch: [ 25/ 25], Step: [ 180/ 234], Loss: 0.3160\n",
            "Epoch: [ 25/ 25], Step: [ 190/ 234], Loss: 0.4484\n",
            "Epoch: [ 25/ 25], Step: [ 200/ 234], Loss: 0.3508\n",
            "Epoch: [ 25/ 25], Step: [ 210/ 234], Loss: 0.3466\n",
            "Epoch: [ 25/ 25], Step: [ 220/ 234], Loss: 0.2738\n",
            "Epoch: [ 25/ 25], Step: [ 230/ 234], Loss: 0.2461\n",
            "Accuracy of the model on the 10000 test images: 90.9%\n",
            "Accuracy of the model on the 60000 train images: 90.5%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkMFnVY1CNFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "600bcf77-f55d-4a89-8d49-a5c32167a6f8"
      },
      "source": [
        "epochs = np.arange(num_epochs)\n",
        "\n",
        "plt.plot(epochs, acc_train, label='Training Error')\n",
        "plt.plot(epochs, acc_test, label='Testing Error')\n",
        "plt.xlabel('Error - training & testing')\n",
        "plt.ylabel('Number of Epochs')\n",
        "plt.legend()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7effa486f208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EaxbZDRYVV7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "70e2be24-6e8e-4b6a-bbd7-cb46c4f8820f"
      },
      "source": [
        "epochs = np.arange(num_epochs)\n",
        "\n",
        "plt.plot(epochs, acc_train, label='Training Error')\n",
        "plt.plot(epochs, acc_test, label='Testing Error')\n",
        "plt.xlabel('Error - training & testing')\n",
        "plt.ylabel('Number of Epochs')\n",
        "plt.legend()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7effa48260b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6rCb13kShUI",
        "colab_type": "text"
      },
      "source": [
        "<b>Problem 5(b):</b> Write new code to perform *6-fold* cross validation on this model.\n",
        "1.  Create a function called ```create_train_val_split()``` that will take a fold number and return an appropriate training set loader and validation set loader (```train_loader, val_loader```) .  It will be used in a loop that will loop over ```range(num_folds)``` to cross validate the model.  It should use contiguous sampling (use ```SequentialSampler```).  Test that it works as expected and show your code.\n",
        "2.  Modify main to create the 6-fold validation loop.  In the loop, you will assign the training and validation loaders, train the model <b>from scratch</b>, and compute the average validation loss over all 6 folds.  You may use the ```epoch_loader()``` function supplied to compute the loss (E_in) on the various data splits.  Test that your code works as expected and show your code.\n",
        "3.  Set the filter hyperparameter ```v = 1``` and report the average validation error (for all 6 folds) below.  Report the error after training for 10 epochs per fold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fejpOebiPw8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your code for create_train_val_split()\n",
        "def create_train_val_split(fold_num):\n",
        "    ...\n",
        "    return train_loader, val_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgeixeEWQEXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your main modified for cross validation\n",
        "def main():\n",
        "    global train_loader\n",
        "    run_training()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYLg_L0ObC9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__=='__main__':\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70NPwkH5DoPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Report your average validation error for all 6 folds here."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAKF6WNncC9D",
        "colab_type": "text"
      },
      "source": [
        "<b>Problem 5(c): </b> Now use cross validation to perform *model selection*.  Select the best integer value for hyperparameter ```v``` from ```v = [0, 1, 2, 3, 4].```   Select the value based on the one that results in the lowest total cross validation error after 10 epochs of training.\n",
        "1.  What are the cross validation errors for these five values of ```v```?  What is the best value for ```v```?   What are the corresponding validation accuracies?\n",
        "2.  Using your best ```v``` value, retrain the model on <b>all</b> training data and report the test error and accuracy.  Is the test error lower or higher than the validation error?  Is the test accuracy lower or higher.  Is this expected?  Explain your answer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTWX-XiSdgcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your cross validation errors for the five values of v and best v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrRPnM6NdmEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your test error and accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWjUIdRv_eck",
        "colab_type": "text"
      },
      "source": [
        "Copyright (c) 2019 Ted Willke"
      ]
    }
  ]
}